{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leorr/AI/blob/main/Projeto_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8cJ5tMhmCNm"
      },
      "source": [
        "LINKS REFERÃŠNCIAS:\n",
        "\n",
        "Classify Images Using Python & Machine Learning - https://www.youtube.com/watch?v=iGWbqhdjf2s\n",
        "\n",
        " CNN Com cachorros e gatos - https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n",
        "\n",
        " what-are-max-pooling-average-pooling-global-max-pooling https://github.com/christianversloot/machine-learning-articles/blob/main/what-are-max-pooling-average-pooling-global-max-pooling-and-global-average-pooling.md\n",
        "\n",
        " Global Max Pool https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D\n",
        "\n",
        "Multiprocessing https://stackoverflow.com/questions/55531427/how-to-define-max-queue-size-workers-and-use-multiprocessing-in-keras-fit-gener"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jp91es8xQEro"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    'Downloads/DATA',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    label_mode='categorical',\n",
        "    seed=123,\n",
        "    image_size=(100,100),\n",
        "    batch_size=32)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'Downloads/DATA',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  label_mode='categorical',\n",
        "  seed=123,\n",
        "  image_size=(100, 100),\n",
        "  batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhRHC52Mw86n",
        "outputId": "2d448143-33b4-451c-f99a-175de6c05ffa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 files belonging to 3 classes.\n",
            "Using 4800 files for training.\n",
            "Found 6000 files belonging to 3 classes.\n",
            "Using 1200 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEHp5g-A7p0n",
        "outputId": "c9393eca-4bd6-4771-c00c-a57e5cb9eb35"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'dog', 'wild']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zTTUdqiv6GzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d515ca3-25fb-4095-aca3-4a5b63f32cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNet(weights='imagenet',\n",
        "                                             include_top=False,\n",
        "                                             input_shape=(100,100,3),\n",
        "                                             pooling=\"max\")\n",
        "x=base_model.output\n",
        "x=tf.keras.layers.Dropout(0.5)(x)\n",
        "preds=tf.keras.layers.Dense(3, activation='softmax')(x)  \n",
        "model = tf.keras.models.Model(\n",
        "    inputs=base_model.input,\n",
        "    outputs=preds\n",
        ")\n",
        "\n",
        "for l in model.layers:\n",
        "  if l.name.split('_')[0] != 'dense':\n",
        "    l.trainable=False\n",
        "  else:\n",
        "    l.trainable=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjxoju5-Abmj",
        "outputId": "6febefb6-2be1-49cc-f302-7280db76525f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 50, 50, 32)        864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 50, 50, 32)       128       \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 50, 50, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 50, 50, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 50, 50, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 50, 50, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 51, 51, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 25, 25, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 25, 25, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 25, 25, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 25, 25, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 25, 25, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 25, 25, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 26, 26, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 12, 12, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 12, 12, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 12, 12, 256)       32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 12, 12, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 12, 12, 256)       65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 6, 6, 256)        2304      \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 6, 6, 256)        1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 6, 6, 512)         131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 6, 6, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 6, 6, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 7, 7, 512)        0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 3, 3, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 3, 3, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 3, 3, 1024)       9216      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 3, 3, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 1024)             0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,231,939\n",
            "Trainable params: 3,075\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iUeXNdZOHCg",
        "outputId": "9b71adee-4d3f-4e8d-d27d-03f7e117360b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "150/150 [==============================] - 19s 120ms/step - loss: 2.1730 - accuracy: 0.4885 - val_loss: 0.8533 - val_accuracy: 0.6774\n",
            "Epoch 2/500\n",
            "150/150 [==============================] - 17s 116ms/step - loss: 1.3523 - accuracy: 0.5979 - val_loss: 0.8502 - val_accuracy: 0.6850\n",
            "Epoch 3/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 1.0092 - accuracy: 0.6379 - val_loss: 0.6966 - val_accuracy: 0.7255\n",
            "Epoch 4/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.8516 - accuracy: 0.6650 - val_loss: 0.6715 - val_accuracy: 0.7221\n",
            "Epoch 5/500\n",
            "150/150 [==============================] - 18s 117ms/step - loss: 0.7785 - accuracy: 0.6785 - val_loss: 0.6256 - val_accuracy: 0.7441\n",
            "Epoch 6/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7342 - accuracy: 0.6965 - val_loss: 0.6433 - val_accuracy: 0.7373\n",
            "Epoch 7/500\n",
            "150/150 [==============================] - 18s 117ms/step - loss: 0.7491 - accuracy: 0.6869 - val_loss: 0.6548 - val_accuracy: 0.7331\n",
            "Epoch 8/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7526 - accuracy: 0.6877 - val_loss: 0.6588 - val_accuracy: 0.7280\n",
            "Epoch 9/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7307 - accuracy: 0.6977 - val_loss: 0.6412 - val_accuracy: 0.7424\n",
            "Epoch 10/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7432 - accuracy: 0.6929 - val_loss: 0.6401 - val_accuracy: 0.7306\n",
            "Epoch 11/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7304 - accuracy: 0.6946 - val_loss: 0.6105 - val_accuracy: 0.7508\n",
            "Epoch 12/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7322 - accuracy: 0.6933 - val_loss: 0.6363 - val_accuracy: 0.7323\n",
            "Epoch 13/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7377 - accuracy: 0.6948 - val_loss: 0.6715 - val_accuracy: 0.7188\n",
            "Epoch 14/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7457 - accuracy: 0.6950 - val_loss: 0.6128 - val_accuracy: 0.7525\n",
            "Epoch 15/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7173 - accuracy: 0.7027 - val_loss: 0.6286 - val_accuracy: 0.7407\n",
            "Epoch 16/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7156 - accuracy: 0.7027 - val_loss: 0.6271 - val_accuracy: 0.7492\n",
            "Epoch 17/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7315 - accuracy: 0.6988 - val_loss: 0.6305 - val_accuracy: 0.7407\n",
            "Epoch 18/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7403 - accuracy: 0.6908 - val_loss: 0.6505 - val_accuracy: 0.7314\n",
            "Epoch 19/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7267 - accuracy: 0.7015 - val_loss: 0.6467 - val_accuracy: 0.7323\n",
            "Epoch 20/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7398 - accuracy: 0.6935 - val_loss: 0.6407 - val_accuracy: 0.7390\n",
            "Epoch 21/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7483 - accuracy: 0.6831 - val_loss: 0.6155 - val_accuracy: 0.7492\n",
            "Epoch 22/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7322 - accuracy: 0.6992 - val_loss: 0.6749 - val_accuracy: 0.7264\n",
            "Epoch 23/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7254 - accuracy: 0.6973 - val_loss: 0.6131 - val_accuracy: 0.7475\n",
            "Epoch 24/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7446 - accuracy: 0.6837 - val_loss: 0.6105 - val_accuracy: 0.7466\n",
            "Epoch 25/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7352 - accuracy: 0.6885 - val_loss: 0.6108 - val_accuracy: 0.7542\n",
            "Epoch 26/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7133 - accuracy: 0.7021 - val_loss: 0.6666 - val_accuracy: 0.7289\n",
            "Epoch 27/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7186 - accuracy: 0.7058 - val_loss: 0.6123 - val_accuracy: 0.7483\n",
            "Epoch 28/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7358 - accuracy: 0.6973 - val_loss: 0.6899 - val_accuracy: 0.7086\n",
            "Epoch 29/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7309 - accuracy: 0.6979 - val_loss: 0.6440 - val_accuracy: 0.7323\n",
            "Epoch 30/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7246 - accuracy: 0.6996 - val_loss: 0.6385 - val_accuracy: 0.7331\n",
            "Epoch 31/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7343 - accuracy: 0.6958 - val_loss: 0.7423 - val_accuracy: 0.7069\n",
            "Epoch 32/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7234 - accuracy: 0.7027 - val_loss: 0.6328 - val_accuracy: 0.7559\n",
            "Epoch 33/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7151 - accuracy: 0.7040 - val_loss: 0.7707 - val_accuracy: 0.6976\n",
            "Epoch 34/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7366 - accuracy: 0.6981 - val_loss: 0.6579 - val_accuracy: 0.7238\n",
            "Epoch 35/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7101 - accuracy: 0.7056 - val_loss: 0.6428 - val_accuracy: 0.7323\n",
            "Epoch 36/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7429 - accuracy: 0.6823 - val_loss: 0.6230 - val_accuracy: 0.7500\n",
            "Epoch 37/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7202 - accuracy: 0.6994 - val_loss: 0.6480 - val_accuracy: 0.7416\n",
            "Epoch 38/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7478 - accuracy: 0.6869 - val_loss: 0.6662 - val_accuracy: 0.7238\n",
            "Epoch 39/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7326 - accuracy: 0.7015 - val_loss: 0.6901 - val_accuracy: 0.7154\n",
            "Epoch 40/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7309 - accuracy: 0.6960 - val_loss: 0.6414 - val_accuracy: 0.7373\n",
            "Epoch 41/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7479 - accuracy: 0.6921 - val_loss: 0.6644 - val_accuracy: 0.7120\n",
            "Epoch 42/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7443 - accuracy: 0.7006 - val_loss: 0.7935 - val_accuracy: 0.6976\n",
            "Epoch 43/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7308 - accuracy: 0.7038 - val_loss: 0.6066 - val_accuracy: 0.7534\n",
            "Epoch 44/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7364 - accuracy: 0.6960 - val_loss: 0.6154 - val_accuracy: 0.7534\n",
            "Epoch 45/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7284 - accuracy: 0.7021 - val_loss: 0.6474 - val_accuracy: 0.7331\n",
            "Epoch 46/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7365 - accuracy: 0.6992 - val_loss: 0.6607 - val_accuracy: 0.7314\n",
            "Epoch 47/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7379 - accuracy: 0.6996 - val_loss: 0.6589 - val_accuracy: 0.7340\n",
            "Epoch 48/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7201 - accuracy: 0.7025 - val_loss: 0.6860 - val_accuracy: 0.7154\n",
            "Epoch 49/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7251 - accuracy: 0.6956 - val_loss: 0.6220 - val_accuracy: 0.7525\n",
            "Epoch 50/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7036 - accuracy: 0.7173 - val_loss: 0.6150 - val_accuracy: 0.7382\n",
            "Epoch 51/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7359 - accuracy: 0.6979 - val_loss: 0.7127 - val_accuracy: 0.7188\n",
            "Epoch 52/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7225 - accuracy: 0.6994 - val_loss: 0.6211 - val_accuracy: 0.7483\n",
            "Epoch 53/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7362 - accuracy: 0.6938 - val_loss: 0.6188 - val_accuracy: 0.7483\n",
            "Epoch 54/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7468 - accuracy: 0.6888 - val_loss: 0.6185 - val_accuracy: 0.7449\n",
            "Epoch 55/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7120 - accuracy: 0.7010 - val_loss: 0.6499 - val_accuracy: 0.7255\n",
            "Epoch 56/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7333 - accuracy: 0.6954 - val_loss: 0.6327 - val_accuracy: 0.7331\n",
            "Epoch 57/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7411 - accuracy: 0.6942 - val_loss: 0.6258 - val_accuracy: 0.7390\n",
            "Epoch 58/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7476 - accuracy: 0.6910 - val_loss: 0.6509 - val_accuracy: 0.7188\n",
            "Epoch 59/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7187 - accuracy: 0.6983 - val_loss: 0.6160 - val_accuracy: 0.7466\n",
            "Epoch 60/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7397 - accuracy: 0.6910 - val_loss: 0.6736 - val_accuracy: 0.7196\n",
            "Epoch 61/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7412 - accuracy: 0.7060 - val_loss: 0.7371 - val_accuracy: 0.7035\n",
            "Epoch 62/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7430 - accuracy: 0.6983 - val_loss: 0.6285 - val_accuracy: 0.7432\n",
            "Epoch 63/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7080 - accuracy: 0.7058 - val_loss: 0.6831 - val_accuracy: 0.7086\n",
            "Epoch 64/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7327 - accuracy: 0.6967 - val_loss: 0.6051 - val_accuracy: 0.7568\n",
            "Epoch 65/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7369 - accuracy: 0.6946 - val_loss: 0.6119 - val_accuracy: 0.7525\n",
            "Epoch 66/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7166 - accuracy: 0.7046 - val_loss: 0.6553 - val_accuracy: 0.7238\n",
            "Epoch 67/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7450 - accuracy: 0.6956 - val_loss: 0.6396 - val_accuracy: 0.7340\n",
            "Epoch 68/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7268 - accuracy: 0.6935 - val_loss: 0.6687 - val_accuracy: 0.7314\n",
            "Epoch 69/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7385 - accuracy: 0.6977 - val_loss: 0.6384 - val_accuracy: 0.7382\n",
            "Epoch 70/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7378 - accuracy: 0.6923 - val_loss: 0.6082 - val_accuracy: 0.7542\n",
            "Epoch 71/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7214 - accuracy: 0.7033 - val_loss: 0.6411 - val_accuracy: 0.7508\n",
            "Epoch 72/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7188 - accuracy: 0.6971 - val_loss: 0.6295 - val_accuracy: 0.7441\n",
            "Epoch 73/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7580 - accuracy: 0.6867 - val_loss: 0.7019 - val_accuracy: 0.6985\n",
            "Epoch 74/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7355 - accuracy: 0.7004 - val_loss: 0.6406 - val_accuracy: 0.7416\n",
            "Epoch 75/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7123 - accuracy: 0.7033 - val_loss: 0.6379 - val_accuracy: 0.7432\n",
            "Epoch 76/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7708 - accuracy: 0.6877 - val_loss: 0.6413 - val_accuracy: 0.7340\n",
            "Epoch 77/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7280 - accuracy: 0.6965 - val_loss: 0.6261 - val_accuracy: 0.7297\n",
            "Epoch 78/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7317 - accuracy: 0.7040 - val_loss: 0.6098 - val_accuracy: 0.7441\n",
            "Epoch 79/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7312 - accuracy: 0.6969 - val_loss: 0.6852 - val_accuracy: 0.7204\n",
            "Epoch 80/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7256 - accuracy: 0.7073 - val_loss: 0.6171 - val_accuracy: 0.7483\n",
            "Epoch 81/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7354 - accuracy: 0.6946 - val_loss: 0.6294 - val_accuracy: 0.7500\n",
            "Epoch 82/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7523 - accuracy: 0.6923 - val_loss: 0.8901 - val_accuracy: 0.6546\n",
            "Epoch 83/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7499 - accuracy: 0.6931 - val_loss: 0.6216 - val_accuracy: 0.7492\n",
            "Epoch 84/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7463 - accuracy: 0.6938 - val_loss: 0.6804 - val_accuracy: 0.7154\n",
            "Epoch 85/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7146 - accuracy: 0.7017 - val_loss: 0.6689 - val_accuracy: 0.7255\n",
            "Epoch 86/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7334 - accuracy: 0.6883 - val_loss: 0.6482 - val_accuracy: 0.7365\n",
            "Epoch 87/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7398 - accuracy: 0.6940 - val_loss: 0.6438 - val_accuracy: 0.7331\n",
            "Epoch 88/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7569 - accuracy: 0.6885 - val_loss: 0.7777 - val_accuracy: 0.6943\n",
            "Epoch 89/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7429 - accuracy: 0.6892 - val_loss: 0.6169 - val_accuracy: 0.7483\n",
            "Epoch 90/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7236 - accuracy: 0.7021 - val_loss: 0.6115 - val_accuracy: 0.7517\n",
            "Epoch 91/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7397 - accuracy: 0.7065 - val_loss: 0.6089 - val_accuracy: 0.7492\n",
            "Epoch 92/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7218 - accuracy: 0.6944 - val_loss: 0.7469 - val_accuracy: 0.6883\n",
            "Epoch 93/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7235 - accuracy: 0.7000 - val_loss: 0.6719 - val_accuracy: 0.7247\n",
            "Epoch 94/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7111 - accuracy: 0.7048 - val_loss: 0.6197 - val_accuracy: 0.7458\n",
            "Epoch 95/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7316 - accuracy: 0.7085 - val_loss: 0.6319 - val_accuracy: 0.7466\n",
            "Epoch 96/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7143 - accuracy: 0.6996 - val_loss: 0.6728 - val_accuracy: 0.7171\n",
            "Epoch 97/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7240 - accuracy: 0.6975 - val_loss: 0.6601 - val_accuracy: 0.7238\n",
            "Epoch 98/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7257 - accuracy: 0.6925 - val_loss: 0.6449 - val_accuracy: 0.7356\n",
            "Epoch 99/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7230 - accuracy: 0.6952 - val_loss: 0.7651 - val_accuracy: 0.7044\n",
            "Epoch 100/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7507 - accuracy: 0.6929 - val_loss: 0.6847 - val_accuracy: 0.7280\n",
            "Epoch 101/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7292 - accuracy: 0.6965 - val_loss: 0.6317 - val_accuracy: 0.7576\n",
            "Epoch 102/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7387 - accuracy: 0.6954 - val_loss: 0.6376 - val_accuracy: 0.7188\n",
            "Epoch 103/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7250 - accuracy: 0.7063 - val_loss: 0.6867 - val_accuracy: 0.7255\n",
            "Epoch 104/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7194 - accuracy: 0.7025 - val_loss: 0.6255 - val_accuracy: 0.7500\n",
            "Epoch 105/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7119 - accuracy: 0.7033 - val_loss: 0.6179 - val_accuracy: 0.7483\n",
            "Epoch 106/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7430 - accuracy: 0.6948 - val_loss: 0.6399 - val_accuracy: 0.7382\n",
            "Epoch 107/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7179 - accuracy: 0.6992 - val_loss: 0.6556 - val_accuracy: 0.7306\n",
            "Epoch 108/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7383 - accuracy: 0.7002 - val_loss: 0.6360 - val_accuracy: 0.7314\n",
            "Epoch 109/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7090 - accuracy: 0.7058 - val_loss: 0.6457 - val_accuracy: 0.7432\n",
            "Epoch 110/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7470 - accuracy: 0.6902 - val_loss: 0.6119 - val_accuracy: 0.7508\n",
            "Epoch 111/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7338 - accuracy: 0.6965 - val_loss: 0.6047 - val_accuracy: 0.7542\n",
            "Epoch 112/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7151 - accuracy: 0.7069 - val_loss: 0.6477 - val_accuracy: 0.7247\n",
            "Epoch 113/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7361 - accuracy: 0.6877 - val_loss: 0.6348 - val_accuracy: 0.7331\n",
            "Epoch 114/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7284 - accuracy: 0.6994 - val_loss: 0.6353 - val_accuracy: 0.7458\n",
            "Epoch 115/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7104 - accuracy: 0.7090 - val_loss: 0.6401 - val_accuracy: 0.7365\n",
            "Epoch 116/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7020 - accuracy: 0.7088 - val_loss: 0.6154 - val_accuracy: 0.7517\n",
            "Epoch 117/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7359 - accuracy: 0.6938 - val_loss: 0.6183 - val_accuracy: 0.7517\n",
            "Epoch 118/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7248 - accuracy: 0.7065 - val_loss: 0.6044 - val_accuracy: 0.7534\n",
            "Epoch 119/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7395 - accuracy: 0.6940 - val_loss: 0.6084 - val_accuracy: 0.7517\n",
            "Epoch 120/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7363 - accuracy: 0.6946 - val_loss: 0.6258 - val_accuracy: 0.7542\n",
            "Epoch 121/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7732 - accuracy: 0.6967 - val_loss: 0.6464 - val_accuracy: 0.7449\n",
            "Epoch 122/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7204 - accuracy: 0.7075 - val_loss: 0.6348 - val_accuracy: 0.7416\n",
            "Epoch 123/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7142 - accuracy: 0.7033 - val_loss: 0.7581 - val_accuracy: 0.7061\n",
            "Epoch 124/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7232 - accuracy: 0.7013 - val_loss: 0.6315 - val_accuracy: 0.7407\n",
            "Epoch 125/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7241 - accuracy: 0.6971 - val_loss: 0.6282 - val_accuracy: 0.7458\n",
            "Epoch 126/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7530 - accuracy: 0.6881 - val_loss: 1.0099 - val_accuracy: 0.6495\n",
            "Epoch 127/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7492 - accuracy: 0.6931 - val_loss: 0.6245 - val_accuracy: 0.7500\n",
            "Epoch 128/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7131 - accuracy: 0.7069 - val_loss: 0.6308 - val_accuracy: 0.7373\n",
            "Epoch 129/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7098 - accuracy: 0.7067 - val_loss: 0.6175 - val_accuracy: 0.7348\n",
            "Epoch 130/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7231 - accuracy: 0.7019 - val_loss: 0.6098 - val_accuracy: 0.7483\n",
            "Epoch 131/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7326 - accuracy: 0.6946 - val_loss: 0.6488 - val_accuracy: 0.7399\n",
            "Epoch 132/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7049 - accuracy: 0.7017 - val_loss: 0.6603 - val_accuracy: 0.7247\n",
            "Epoch 133/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7452 - accuracy: 0.6975 - val_loss: 0.6541 - val_accuracy: 0.7289\n",
            "Epoch 134/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7279 - accuracy: 0.7002 - val_loss: 0.6076 - val_accuracy: 0.7475\n",
            "Epoch 135/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7281 - accuracy: 0.6985 - val_loss: 0.6339 - val_accuracy: 0.7373\n",
            "Epoch 136/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7474 - accuracy: 0.6885 - val_loss: 0.6178 - val_accuracy: 0.7508\n",
            "Epoch 137/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7358 - accuracy: 0.6931 - val_loss: 0.7357 - val_accuracy: 0.7120\n",
            "Epoch 138/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7259 - accuracy: 0.7010 - val_loss: 0.6645 - val_accuracy: 0.7272\n",
            "Epoch 139/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7233 - accuracy: 0.7023 - val_loss: 0.6943 - val_accuracy: 0.7204\n",
            "Epoch 140/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7341 - accuracy: 0.6965 - val_loss: 0.7068 - val_accuracy: 0.7179\n",
            "Epoch 141/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7641 - accuracy: 0.6888 - val_loss: 0.6868 - val_accuracy: 0.7086\n",
            "Epoch 142/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7271 - accuracy: 0.7015 - val_loss: 0.6175 - val_accuracy: 0.7424\n",
            "Epoch 143/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7331 - accuracy: 0.7006 - val_loss: 0.6408 - val_accuracy: 0.7424\n",
            "Epoch 144/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7186 - accuracy: 0.7098 - val_loss: 0.6970 - val_accuracy: 0.7230\n",
            "Epoch 145/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7375 - accuracy: 0.6975 - val_loss: 0.6786 - val_accuracy: 0.7154\n",
            "Epoch 146/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7286 - accuracy: 0.7000 - val_loss: 0.6261 - val_accuracy: 0.7483\n",
            "Epoch 147/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7284 - accuracy: 0.6888 - val_loss: 0.6963 - val_accuracy: 0.7086\n",
            "Epoch 148/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7172 - accuracy: 0.6946 - val_loss: 0.7474 - val_accuracy: 0.6807\n",
            "Epoch 149/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7291 - accuracy: 0.7048 - val_loss: 0.6486 - val_accuracy: 0.7390\n",
            "Epoch 150/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7351 - accuracy: 0.6956 - val_loss: 0.6574 - val_accuracy: 0.7280\n",
            "Epoch 151/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7086 - accuracy: 0.7075 - val_loss: 0.6108 - val_accuracy: 0.7458\n",
            "Epoch 152/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7232 - accuracy: 0.7008 - val_loss: 0.6341 - val_accuracy: 0.7373\n",
            "Epoch 153/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7237 - accuracy: 0.6998 - val_loss: 0.6051 - val_accuracy: 0.7576\n",
            "Epoch 154/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7377 - accuracy: 0.7019 - val_loss: 0.7195 - val_accuracy: 0.7154\n",
            "Epoch 155/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7323 - accuracy: 0.6906 - val_loss: 0.6231 - val_accuracy: 0.7508\n",
            "Epoch 156/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7220 - accuracy: 0.6933 - val_loss: 0.6226 - val_accuracy: 0.7492\n",
            "Epoch 157/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7368 - accuracy: 0.7052 - val_loss: 0.6036 - val_accuracy: 0.7542\n",
            "Epoch 158/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7394 - accuracy: 0.6956 - val_loss: 0.6775 - val_accuracy: 0.7035\n",
            "Epoch 159/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7404 - accuracy: 0.6919 - val_loss: 0.7412 - val_accuracy: 0.6943\n",
            "Epoch 160/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7099 - accuracy: 0.7179 - val_loss: 0.6083 - val_accuracy: 0.7517\n",
            "Epoch 161/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7484 - accuracy: 0.6831 - val_loss: 0.6142 - val_accuracy: 0.7407\n",
            "Epoch 162/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7365 - accuracy: 0.6952 - val_loss: 0.6836 - val_accuracy: 0.7188\n",
            "Epoch 163/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7326 - accuracy: 0.6933 - val_loss: 0.6576 - val_accuracy: 0.7280\n",
            "Epoch 164/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7540 - accuracy: 0.6958 - val_loss: 0.6283 - val_accuracy: 0.7458\n",
            "Epoch 165/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7195 - accuracy: 0.7083 - val_loss: 0.6319 - val_accuracy: 0.7441\n",
            "Epoch 166/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7174 - accuracy: 0.7008 - val_loss: 0.7188 - val_accuracy: 0.7078\n",
            "Epoch 167/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7484 - accuracy: 0.6985 - val_loss: 0.6282 - val_accuracy: 0.7382\n",
            "Epoch 168/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7371 - accuracy: 0.6956 - val_loss: 0.6107 - val_accuracy: 0.7568\n",
            "Epoch 169/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7265 - accuracy: 0.7017 - val_loss: 0.6306 - val_accuracy: 0.7390\n",
            "Epoch 170/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7255 - accuracy: 0.7038 - val_loss: 0.6717 - val_accuracy: 0.7238\n",
            "Epoch 171/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7455 - accuracy: 0.6973 - val_loss: 0.6545 - val_accuracy: 0.7230\n",
            "Epoch 172/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7483 - accuracy: 0.6898 - val_loss: 0.6284 - val_accuracy: 0.7323\n",
            "Epoch 173/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7231 - accuracy: 0.7052 - val_loss: 0.6107 - val_accuracy: 0.7500\n",
            "Epoch 174/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7141 - accuracy: 0.6998 - val_loss: 0.7224 - val_accuracy: 0.7103\n",
            "Epoch 175/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7183 - accuracy: 0.7031 - val_loss: 0.6294 - val_accuracy: 0.7373\n",
            "Epoch 176/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7259 - accuracy: 0.6973 - val_loss: 0.6602 - val_accuracy: 0.7306\n",
            "Epoch 177/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7446 - accuracy: 0.6919 - val_loss: 0.6301 - val_accuracy: 0.7492\n",
            "Epoch 178/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7170 - accuracy: 0.7006 - val_loss: 0.6436 - val_accuracy: 0.7264\n",
            "Epoch 179/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7268 - accuracy: 0.6969 - val_loss: 0.7096 - val_accuracy: 0.7196\n",
            "Epoch 180/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7082 - accuracy: 0.7129 - val_loss: 0.6310 - val_accuracy: 0.7466\n",
            "Epoch 181/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7110 - accuracy: 0.7108 - val_loss: 0.6857 - val_accuracy: 0.7171\n",
            "Epoch 182/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7439 - accuracy: 0.6971 - val_loss: 0.6210 - val_accuracy: 0.7466\n",
            "Epoch 183/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7282 - accuracy: 0.7027 - val_loss: 0.6799 - val_accuracy: 0.7323\n",
            "Epoch 184/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7771 - accuracy: 0.6848 - val_loss: 0.6371 - val_accuracy: 0.7373\n",
            "Epoch 185/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7357 - accuracy: 0.7013 - val_loss: 0.6515 - val_accuracy: 0.7390\n",
            "Epoch 186/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7251 - accuracy: 0.6944 - val_loss: 0.6744 - val_accuracy: 0.7238\n",
            "Epoch 187/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7082 - accuracy: 0.7106 - val_loss: 0.6545 - val_accuracy: 0.7238\n",
            "Epoch 188/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7319 - accuracy: 0.7010 - val_loss: 0.6230 - val_accuracy: 0.7373\n",
            "Epoch 189/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7287 - accuracy: 0.6998 - val_loss: 0.6054 - val_accuracy: 0.7568\n",
            "Epoch 190/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7189 - accuracy: 0.6992 - val_loss: 0.6143 - val_accuracy: 0.7475\n",
            "Epoch 191/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7302 - accuracy: 0.7025 - val_loss: 0.6432 - val_accuracy: 0.7314\n",
            "Epoch 192/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7298 - accuracy: 0.7002 - val_loss: 0.6492 - val_accuracy: 0.7331\n",
            "Epoch 193/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7751 - accuracy: 0.6858 - val_loss: 0.6918 - val_accuracy: 0.7247\n",
            "Epoch 194/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7263 - accuracy: 0.7023 - val_loss: 0.6805 - val_accuracy: 0.7204\n",
            "Epoch 195/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7308 - accuracy: 0.6979 - val_loss: 0.6832 - val_accuracy: 0.7145\n",
            "Epoch 196/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7162 - accuracy: 0.7083 - val_loss: 0.6791 - val_accuracy: 0.7230\n",
            "Epoch 197/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7370 - accuracy: 0.7015 - val_loss: 0.6532 - val_accuracy: 0.7272\n",
            "Epoch 198/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7243 - accuracy: 0.6954 - val_loss: 0.6892 - val_accuracy: 0.7095\n",
            "Epoch 199/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7284 - accuracy: 0.6921 - val_loss: 0.6333 - val_accuracy: 0.7458\n",
            "Epoch 200/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7201 - accuracy: 0.6958 - val_loss: 0.6443 - val_accuracy: 0.7323\n",
            "Epoch 201/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.6995 - accuracy: 0.7092 - val_loss: 0.7240 - val_accuracy: 0.7086\n",
            "Epoch 202/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7297 - accuracy: 0.7038 - val_loss: 0.6569 - val_accuracy: 0.7314\n",
            "Epoch 203/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7223 - accuracy: 0.6994 - val_loss: 0.6367 - val_accuracy: 0.7458\n",
            "Epoch 204/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7343 - accuracy: 0.7004 - val_loss: 0.7155 - val_accuracy: 0.7078\n",
            "Epoch 205/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7248 - accuracy: 0.7075 - val_loss: 0.6679 - val_accuracy: 0.7365\n",
            "Epoch 206/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7187 - accuracy: 0.7023 - val_loss: 0.6494 - val_accuracy: 0.7416\n",
            "Epoch 207/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7300 - accuracy: 0.6938 - val_loss: 0.6484 - val_accuracy: 0.7255\n",
            "Epoch 208/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7260 - accuracy: 0.6967 - val_loss: 0.6697 - val_accuracy: 0.7289\n",
            "Epoch 209/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7183 - accuracy: 0.7046 - val_loss: 0.6173 - val_accuracy: 0.7610\n",
            "Epoch 210/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7170 - accuracy: 0.7031 - val_loss: 0.6271 - val_accuracy: 0.7534\n",
            "Epoch 211/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7268 - accuracy: 0.7025 - val_loss: 0.6195 - val_accuracy: 0.7458\n",
            "Epoch 212/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7326 - accuracy: 0.7038 - val_loss: 0.6571 - val_accuracy: 0.7297\n",
            "Epoch 213/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7459 - accuracy: 0.6933 - val_loss: 0.6448 - val_accuracy: 0.7390\n",
            "Epoch 214/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7272 - accuracy: 0.7046 - val_loss: 0.6978 - val_accuracy: 0.6993\n",
            "Epoch 215/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7099 - accuracy: 0.7219 - val_loss: 0.6755 - val_accuracy: 0.7272\n",
            "Epoch 216/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7226 - accuracy: 0.7054 - val_loss: 0.6278 - val_accuracy: 0.7365\n",
            "Epoch 217/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7181 - accuracy: 0.6992 - val_loss: 0.6284 - val_accuracy: 0.7508\n",
            "Epoch 218/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7101 - accuracy: 0.7052 - val_loss: 0.6047 - val_accuracy: 0.7492\n",
            "Epoch 219/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7127 - accuracy: 0.7023 - val_loss: 0.6171 - val_accuracy: 0.7542\n",
            "Epoch 220/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7335 - accuracy: 0.6969 - val_loss: 0.6326 - val_accuracy: 0.7466\n",
            "Epoch 221/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7115 - accuracy: 0.7092 - val_loss: 0.6227 - val_accuracy: 0.7416\n",
            "Epoch 222/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7255 - accuracy: 0.7069 - val_loss: 0.6226 - val_accuracy: 0.7441\n",
            "Epoch 223/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7299 - accuracy: 0.6973 - val_loss: 0.6211 - val_accuracy: 0.7492\n",
            "Epoch 224/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7281 - accuracy: 0.6994 - val_loss: 0.6013 - val_accuracy: 0.7525\n",
            "Epoch 225/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7361 - accuracy: 0.6975 - val_loss: 0.6140 - val_accuracy: 0.7483\n",
            "Epoch 226/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7251 - accuracy: 0.7006 - val_loss: 0.6165 - val_accuracy: 0.7466\n",
            "Epoch 227/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7124 - accuracy: 0.7019 - val_loss: 0.6247 - val_accuracy: 0.7432\n",
            "Epoch 228/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7121 - accuracy: 0.7031 - val_loss: 0.6490 - val_accuracy: 0.7356\n",
            "Epoch 229/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7105 - accuracy: 0.7067 - val_loss: 0.6748 - val_accuracy: 0.7204\n",
            "Epoch 230/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7214 - accuracy: 0.7104 - val_loss: 0.6723 - val_accuracy: 0.7145\n",
            "Epoch 231/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7296 - accuracy: 0.6992 - val_loss: 0.6104 - val_accuracy: 0.7601\n",
            "Epoch 232/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7196 - accuracy: 0.7088 - val_loss: 0.6535 - val_accuracy: 0.7255\n",
            "Epoch 233/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7368 - accuracy: 0.6935 - val_loss: 0.6694 - val_accuracy: 0.7289\n",
            "Epoch 234/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7416 - accuracy: 0.6902 - val_loss: 0.6843 - val_accuracy: 0.7137\n",
            "Epoch 235/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7524 - accuracy: 0.6906 - val_loss: 0.6517 - val_accuracy: 0.7289\n",
            "Epoch 236/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7421 - accuracy: 0.7100 - val_loss: 0.6292 - val_accuracy: 0.7356\n",
            "Epoch 237/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7372 - accuracy: 0.6981 - val_loss: 0.8099 - val_accuracy: 0.6765\n",
            "Epoch 238/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7433 - accuracy: 0.6900 - val_loss: 0.6463 - val_accuracy: 0.7390\n",
            "Epoch 239/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7182 - accuracy: 0.7067 - val_loss: 0.6551 - val_accuracy: 0.7348\n",
            "Epoch 240/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7121 - accuracy: 0.7077 - val_loss: 0.6332 - val_accuracy: 0.7340\n",
            "Epoch 241/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7343 - accuracy: 0.7013 - val_loss: 0.6985 - val_accuracy: 0.7297\n",
            "Epoch 242/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7222 - accuracy: 0.7042 - val_loss: 0.6341 - val_accuracy: 0.7382\n",
            "Epoch 243/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7047 - accuracy: 0.7021 - val_loss: 0.6496 - val_accuracy: 0.7348\n",
            "Epoch 244/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7415 - accuracy: 0.6904 - val_loss: 0.6389 - val_accuracy: 0.7390\n",
            "Epoch 245/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7086 - accuracy: 0.7048 - val_loss: 0.6710 - val_accuracy: 0.7280\n",
            "Epoch 246/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7315 - accuracy: 0.6967 - val_loss: 0.6210 - val_accuracy: 0.7534\n",
            "Epoch 247/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7228 - accuracy: 0.6971 - val_loss: 0.6191 - val_accuracy: 0.7424\n",
            "Epoch 248/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7190 - accuracy: 0.7033 - val_loss: 0.6292 - val_accuracy: 0.7475\n",
            "Epoch 249/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7148 - accuracy: 0.7067 - val_loss: 0.6006 - val_accuracy: 0.7584\n",
            "Epoch 250/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7329 - accuracy: 0.7035 - val_loss: 0.6007 - val_accuracy: 0.7559\n",
            "Epoch 251/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7248 - accuracy: 0.7015 - val_loss: 0.6138 - val_accuracy: 0.7424\n",
            "Epoch 252/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7196 - accuracy: 0.7065 - val_loss: 0.6502 - val_accuracy: 0.7424\n",
            "Epoch 253/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7528 - accuracy: 0.6865 - val_loss: 0.6832 - val_accuracy: 0.7171\n",
            "Epoch 254/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7243 - accuracy: 0.7004 - val_loss: 0.6166 - val_accuracy: 0.7483\n",
            "Epoch 255/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7252 - accuracy: 0.6956 - val_loss: 0.6097 - val_accuracy: 0.7500\n",
            "Epoch 256/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7474 - accuracy: 0.6921 - val_loss: 0.6680 - val_accuracy: 0.7188\n",
            "Epoch 257/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7386 - accuracy: 0.6973 - val_loss: 0.6130 - val_accuracy: 0.7432\n",
            "Epoch 258/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7218 - accuracy: 0.7006 - val_loss: 0.6806 - val_accuracy: 0.7272\n",
            "Epoch 259/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7181 - accuracy: 0.7069 - val_loss: 0.6055 - val_accuracy: 0.7576\n",
            "Epoch 260/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7208 - accuracy: 0.7088 - val_loss: 0.6211 - val_accuracy: 0.7441\n",
            "Epoch 261/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7440 - accuracy: 0.6960 - val_loss: 0.6152 - val_accuracy: 0.7559\n",
            "Epoch 262/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7282 - accuracy: 0.6996 - val_loss: 0.6253 - val_accuracy: 0.7449\n",
            "Epoch 263/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7256 - accuracy: 0.6979 - val_loss: 0.6758 - val_accuracy: 0.7213\n",
            "Epoch 264/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7338 - accuracy: 0.6927 - val_loss: 0.6290 - val_accuracy: 0.7424\n",
            "Epoch 265/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7263 - accuracy: 0.7025 - val_loss: 0.6523 - val_accuracy: 0.7356\n",
            "Epoch 266/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7189 - accuracy: 0.7077 - val_loss: 0.6853 - val_accuracy: 0.7221\n",
            "Epoch 267/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7306 - accuracy: 0.7002 - val_loss: 0.6400 - val_accuracy: 0.7424\n",
            "Epoch 268/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7229 - accuracy: 0.7071 - val_loss: 0.6255 - val_accuracy: 0.7534\n",
            "Epoch 269/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7352 - accuracy: 0.7006 - val_loss: 0.6250 - val_accuracy: 0.7500\n",
            "Epoch 270/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7311 - accuracy: 0.6967 - val_loss: 0.6477 - val_accuracy: 0.7382\n",
            "Epoch 271/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7399 - accuracy: 0.7006 - val_loss: 0.6732 - val_accuracy: 0.7204\n",
            "Epoch 272/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7699 - accuracy: 0.6867 - val_loss: 0.6894 - val_accuracy: 0.7238\n",
            "Epoch 273/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7222 - accuracy: 0.6877 - val_loss: 0.6413 - val_accuracy: 0.7289\n",
            "Epoch 274/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7088 - accuracy: 0.7102 - val_loss: 0.6677 - val_accuracy: 0.7162\n",
            "Epoch 275/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7249 - accuracy: 0.7013 - val_loss: 0.6164 - val_accuracy: 0.7390\n",
            "Epoch 276/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7317 - accuracy: 0.6938 - val_loss: 0.6523 - val_accuracy: 0.7356\n",
            "Epoch 277/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7386 - accuracy: 0.6925 - val_loss: 0.6172 - val_accuracy: 0.7475\n",
            "Epoch 278/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7050 - accuracy: 0.7050 - val_loss: 0.6541 - val_accuracy: 0.7432\n",
            "Epoch 279/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7065 - accuracy: 0.7069 - val_loss: 0.6337 - val_accuracy: 0.7323\n",
            "Epoch 280/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7096 - accuracy: 0.7065 - val_loss: 0.6798 - val_accuracy: 0.7171\n",
            "Epoch 281/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7211 - accuracy: 0.7019 - val_loss: 0.6784 - val_accuracy: 0.7179\n",
            "Epoch 282/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7231 - accuracy: 0.7006 - val_loss: 0.6169 - val_accuracy: 0.7492\n",
            "Epoch 283/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7369 - accuracy: 0.6983 - val_loss: 0.6188 - val_accuracy: 0.7576\n",
            "Epoch 284/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7268 - accuracy: 0.6988 - val_loss: 0.6308 - val_accuracy: 0.7475\n",
            "Epoch 285/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7158 - accuracy: 0.7052 - val_loss: 0.6276 - val_accuracy: 0.7407\n",
            "Epoch 286/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7474 - accuracy: 0.6948 - val_loss: 0.6186 - val_accuracy: 0.7576\n",
            "Epoch 287/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7415 - accuracy: 0.6983 - val_loss: 0.6348 - val_accuracy: 0.7551\n",
            "Epoch 288/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7134 - accuracy: 0.7025 - val_loss: 0.6222 - val_accuracy: 0.7407\n",
            "Epoch 289/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7262 - accuracy: 0.7017 - val_loss: 0.6330 - val_accuracy: 0.7382\n",
            "Epoch 290/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7286 - accuracy: 0.6946 - val_loss: 0.6298 - val_accuracy: 0.7416\n",
            "Epoch 291/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7223 - accuracy: 0.7044 - val_loss: 0.6274 - val_accuracy: 0.7441\n",
            "Epoch 292/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7325 - accuracy: 0.7004 - val_loss: 0.6515 - val_accuracy: 0.7365\n",
            "Epoch 293/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7229 - accuracy: 0.7004 - val_loss: 0.6181 - val_accuracy: 0.7559\n",
            "Epoch 294/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7216 - accuracy: 0.7029 - val_loss: 0.6869 - val_accuracy: 0.7052\n",
            "Epoch 295/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7241 - accuracy: 0.7038 - val_loss: 0.7177 - val_accuracy: 0.7095\n",
            "Epoch 296/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7434 - accuracy: 0.7013 - val_loss: 0.6296 - val_accuracy: 0.7348\n",
            "Epoch 297/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7324 - accuracy: 0.7090 - val_loss: 0.6490 - val_accuracy: 0.7272\n",
            "Epoch 298/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7435 - accuracy: 0.6896 - val_loss: 0.6987 - val_accuracy: 0.7052\n",
            "Epoch 299/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7502 - accuracy: 0.6940 - val_loss: 0.6526 - val_accuracy: 0.7382\n",
            "Epoch 300/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7029 - accuracy: 0.7063 - val_loss: 0.6603 - val_accuracy: 0.7230\n",
            "Epoch 301/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7214 - accuracy: 0.7023 - val_loss: 0.6239 - val_accuracy: 0.7466\n",
            "Epoch 302/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7245 - accuracy: 0.7029 - val_loss: 0.7238 - val_accuracy: 0.7069\n",
            "Epoch 303/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7293 - accuracy: 0.7035 - val_loss: 0.6407 - val_accuracy: 0.7483\n",
            "Epoch 304/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7351 - accuracy: 0.6998 - val_loss: 0.6166 - val_accuracy: 0.7492\n",
            "Epoch 305/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7153 - accuracy: 0.7115 - val_loss: 0.7063 - val_accuracy: 0.7095\n",
            "Epoch 306/500\n",
            "150/150 [==============================] - 18s 118ms/step - loss: 0.7519 - accuracy: 0.6904 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
            "Epoch 307/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7116 - accuracy: 0.7013 - val_loss: 0.6111 - val_accuracy: 0.7525\n",
            "Epoch 308/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7623 - accuracy: 0.6919 - val_loss: 0.6784 - val_accuracy: 0.7188\n",
            "Epoch 309/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7253 - accuracy: 0.7019 - val_loss: 0.6315 - val_accuracy: 0.7382\n",
            "Epoch 310/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7204 - accuracy: 0.7083 - val_loss: 0.6889 - val_accuracy: 0.7297\n",
            "Epoch 311/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7289 - accuracy: 0.6985 - val_loss: 0.6899 - val_accuracy: 0.7061\n",
            "Epoch 312/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7207 - accuracy: 0.6981 - val_loss: 0.6202 - val_accuracy: 0.7466\n",
            "Epoch 313/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7299 - accuracy: 0.6998 - val_loss: 0.6457 - val_accuracy: 0.7399\n",
            "Epoch 314/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7183 - accuracy: 0.7008 - val_loss: 0.6209 - val_accuracy: 0.7475\n",
            "Epoch 315/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7150 - accuracy: 0.7110 - val_loss: 0.6910 - val_accuracy: 0.7171\n",
            "Epoch 316/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7530 - accuracy: 0.6981 - val_loss: 0.7689 - val_accuracy: 0.6875\n",
            "Epoch 317/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7225 - accuracy: 0.7019 - val_loss: 0.6195 - val_accuracy: 0.7432\n",
            "Epoch 318/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7190 - accuracy: 0.7029 - val_loss: 0.6961 - val_accuracy: 0.7154\n",
            "Epoch 319/500\n",
            "150/150 [==============================] - 19s 123ms/step - loss: 0.7347 - accuracy: 0.6977 - val_loss: 0.7621 - val_accuracy: 0.6816\n",
            "Epoch 320/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7298 - accuracy: 0.7052 - val_loss: 0.6158 - val_accuracy: 0.7559\n",
            "Epoch 321/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7045 - accuracy: 0.7110 - val_loss: 0.6380 - val_accuracy: 0.7416\n",
            "Epoch 322/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7413 - accuracy: 0.6990 - val_loss: 0.6209 - val_accuracy: 0.7525\n",
            "Epoch 323/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7365 - accuracy: 0.6931 - val_loss: 0.7842 - val_accuracy: 0.6807\n",
            "Epoch 324/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7150 - accuracy: 0.7013 - val_loss: 0.6378 - val_accuracy: 0.7382\n",
            "Epoch 325/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7358 - accuracy: 0.6888 - val_loss: 0.6860 - val_accuracy: 0.7035\n",
            "Epoch 326/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7156 - accuracy: 0.7133 - val_loss: 0.6200 - val_accuracy: 0.7475\n",
            "Epoch 327/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7240 - accuracy: 0.7013 - val_loss: 0.6142 - val_accuracy: 0.7551\n",
            "Epoch 328/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7168 - accuracy: 0.7017 - val_loss: 0.6289 - val_accuracy: 0.7517\n",
            "Epoch 329/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7530 - accuracy: 0.6946 - val_loss: 0.6183 - val_accuracy: 0.7627\n",
            "Epoch 330/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7147 - accuracy: 0.7033 - val_loss: 0.6595 - val_accuracy: 0.7348\n",
            "Epoch 331/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7340 - accuracy: 0.6975 - val_loss: 0.6623 - val_accuracy: 0.7238\n",
            "Epoch 332/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7282 - accuracy: 0.7000 - val_loss: 0.6554 - val_accuracy: 0.7365\n",
            "Epoch 333/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7551 - accuracy: 0.6902 - val_loss: 0.6199 - val_accuracy: 0.7390\n",
            "Epoch 334/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7357 - accuracy: 0.6996 - val_loss: 0.6185 - val_accuracy: 0.7618\n",
            "Epoch 335/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7300 - accuracy: 0.7033 - val_loss: 0.6215 - val_accuracy: 0.7416\n",
            "Epoch 336/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7429 - accuracy: 0.6948 - val_loss: 0.6651 - val_accuracy: 0.7314\n",
            "Epoch 337/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7184 - accuracy: 0.7002 - val_loss: 0.6120 - val_accuracy: 0.7534\n",
            "Epoch 338/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7267 - accuracy: 0.7002 - val_loss: 0.6621 - val_accuracy: 0.7145\n",
            "Epoch 339/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7557 - accuracy: 0.6917 - val_loss: 0.6213 - val_accuracy: 0.7525\n",
            "Epoch 340/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7170 - accuracy: 0.7100 - val_loss: 0.6333 - val_accuracy: 0.7373\n",
            "Epoch 341/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7362 - accuracy: 0.6996 - val_loss: 0.6410 - val_accuracy: 0.7348\n",
            "Epoch 342/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7373 - accuracy: 0.6921 - val_loss: 0.6992 - val_accuracy: 0.7128\n",
            "Epoch 343/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7328 - accuracy: 0.7021 - val_loss: 0.6627 - val_accuracy: 0.7356\n",
            "Epoch 344/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7351 - accuracy: 0.6973 - val_loss: 0.7085 - val_accuracy: 0.7086\n",
            "Epoch 345/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7280 - accuracy: 0.7046 - val_loss: 0.6502 - val_accuracy: 0.7238\n",
            "Epoch 346/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7591 - accuracy: 0.6935 - val_loss: 0.6399 - val_accuracy: 0.7264\n",
            "Epoch 347/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7279 - accuracy: 0.7021 - val_loss: 0.6705 - val_accuracy: 0.7179\n",
            "Epoch 348/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7186 - accuracy: 0.6933 - val_loss: 0.6473 - val_accuracy: 0.7407\n",
            "Epoch 349/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7285 - accuracy: 0.6985 - val_loss: 0.6170 - val_accuracy: 0.7525\n",
            "Epoch 350/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7359 - accuracy: 0.7025 - val_loss: 0.6365 - val_accuracy: 0.7390\n",
            "Epoch 351/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7422 - accuracy: 0.7000 - val_loss: 0.6434 - val_accuracy: 0.7188\n",
            "Epoch 352/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7368 - accuracy: 0.6923 - val_loss: 0.6202 - val_accuracy: 0.7475\n",
            "Epoch 353/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7423 - accuracy: 0.6898 - val_loss: 0.6391 - val_accuracy: 0.7432\n",
            "Epoch 354/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7158 - accuracy: 0.7013 - val_loss: 0.6188 - val_accuracy: 0.7525\n",
            "Epoch 355/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7226 - accuracy: 0.6973 - val_loss: 0.6373 - val_accuracy: 0.7373\n",
            "Epoch 356/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7168 - accuracy: 0.6958 - val_loss: 0.6331 - val_accuracy: 0.7390\n",
            "Epoch 357/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7337 - accuracy: 0.6992 - val_loss: 0.6246 - val_accuracy: 0.7500\n",
            "Epoch 358/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7487 - accuracy: 0.6960 - val_loss: 0.7547 - val_accuracy: 0.7052\n",
            "Epoch 359/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7379 - accuracy: 0.7002 - val_loss: 0.6331 - val_accuracy: 0.7542\n",
            "Epoch 360/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7242 - accuracy: 0.6994 - val_loss: 0.6190 - val_accuracy: 0.7517\n",
            "Epoch 361/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7167 - accuracy: 0.7079 - val_loss: 0.6219 - val_accuracy: 0.7348\n",
            "Epoch 362/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7396 - accuracy: 0.7004 - val_loss: 0.6524 - val_accuracy: 0.7373\n",
            "Epoch 363/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7217 - accuracy: 0.7021 - val_loss: 0.6125 - val_accuracy: 0.7551\n",
            "Epoch 364/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7312 - accuracy: 0.6919 - val_loss: 0.6184 - val_accuracy: 0.7466\n",
            "Epoch 365/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7247 - accuracy: 0.7065 - val_loss: 0.6526 - val_accuracy: 0.7382\n",
            "Epoch 366/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7170 - accuracy: 0.7056 - val_loss: 0.6531 - val_accuracy: 0.7373\n",
            "Epoch 367/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7205 - accuracy: 0.6952 - val_loss: 0.6124 - val_accuracy: 0.7618\n",
            "Epoch 368/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7564 - accuracy: 0.6877 - val_loss: 0.7340 - val_accuracy: 0.6850\n",
            "Epoch 369/500\n",
            "150/150 [==============================] - 18s 122ms/step - loss: 0.7421 - accuracy: 0.6981 - val_loss: 0.6350 - val_accuracy: 0.7365\n",
            "Epoch 370/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7306 - accuracy: 0.6996 - val_loss: 0.6316 - val_accuracy: 0.7483\n",
            "Epoch 371/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7238 - accuracy: 0.7019 - val_loss: 0.6788 - val_accuracy: 0.7188\n",
            "Epoch 372/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7132 - accuracy: 0.7006 - val_loss: 0.6901 - val_accuracy: 0.7078\n",
            "Epoch 373/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7256 - accuracy: 0.7004 - val_loss: 0.6186 - val_accuracy: 0.7517\n",
            "Epoch 374/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7226 - accuracy: 0.7000 - val_loss: 0.6502 - val_accuracy: 0.7280\n",
            "Epoch 375/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.6985 - accuracy: 0.7127 - val_loss: 0.6168 - val_accuracy: 0.7508\n",
            "Epoch 376/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7321 - accuracy: 0.6933 - val_loss: 0.6607 - val_accuracy: 0.7247\n",
            "Epoch 377/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7268 - accuracy: 0.6965 - val_loss: 0.6293 - val_accuracy: 0.7365\n",
            "Epoch 378/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7271 - accuracy: 0.6981 - val_loss: 0.6395 - val_accuracy: 0.7416\n",
            "Epoch 379/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7143 - accuracy: 0.7054 - val_loss: 0.6190 - val_accuracy: 0.7466\n",
            "Epoch 380/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7300 - accuracy: 0.7000 - val_loss: 0.6297 - val_accuracy: 0.7416\n",
            "Epoch 381/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7349 - accuracy: 0.6958 - val_loss: 0.6214 - val_accuracy: 0.7483\n",
            "Epoch 382/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7043 - accuracy: 0.7079 - val_loss: 0.6342 - val_accuracy: 0.7432\n",
            "Epoch 383/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7166 - accuracy: 0.6954 - val_loss: 0.6401 - val_accuracy: 0.7382\n",
            "Epoch 384/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7404 - accuracy: 0.6958 - val_loss: 0.6476 - val_accuracy: 0.7365\n",
            "Epoch 385/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7189 - accuracy: 0.6977 - val_loss: 0.6215 - val_accuracy: 0.7576\n",
            "Epoch 386/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7308 - accuracy: 0.7035 - val_loss: 0.6741 - val_accuracy: 0.7204\n",
            "Epoch 387/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7047 - accuracy: 0.7115 - val_loss: 0.6391 - val_accuracy: 0.7424\n",
            "Epoch 388/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7392 - accuracy: 0.6965 - val_loss: 0.6830 - val_accuracy: 0.7137\n",
            "Epoch 389/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7590 - accuracy: 0.6983 - val_loss: 0.6406 - val_accuracy: 0.7424\n",
            "Epoch 390/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7318 - accuracy: 0.6983 - val_loss: 0.6614 - val_accuracy: 0.7213\n",
            "Epoch 391/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7173 - accuracy: 0.7115 - val_loss: 0.6181 - val_accuracy: 0.7483\n",
            "Epoch 392/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7728 - accuracy: 0.6856 - val_loss: 0.7083 - val_accuracy: 0.7069\n",
            "Epoch 393/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7493 - accuracy: 0.6969 - val_loss: 0.6976 - val_accuracy: 0.7238\n",
            "Epoch 394/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7382 - accuracy: 0.6942 - val_loss: 0.6374 - val_accuracy: 0.7348\n",
            "Epoch 395/500\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.7117 - accuracy: 0.7002 - val_loss: 0.6348 - val_accuracy: 0.7449\n",
            "Epoch 396/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7333 - accuracy: 0.7027 - val_loss: 0.6770 - val_accuracy: 0.7213\n",
            "Epoch 397/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7422 - accuracy: 0.6981 - val_loss: 0.6622 - val_accuracy: 0.7280\n",
            "Epoch 398/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7143 - accuracy: 0.7013 - val_loss: 0.6384 - val_accuracy: 0.7331\n",
            "Epoch 399/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7048 - accuracy: 0.7113 - val_loss: 0.6357 - val_accuracy: 0.7593\n",
            "Epoch 400/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7335 - accuracy: 0.6996 - val_loss: 0.6734 - val_accuracy: 0.7255\n",
            "Epoch 401/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7218 - accuracy: 0.7023 - val_loss: 0.6218 - val_accuracy: 0.7534\n",
            "Epoch 402/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7518 - accuracy: 0.6954 - val_loss: 0.6511 - val_accuracy: 0.7399\n",
            "Epoch 403/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7334 - accuracy: 0.7060 - val_loss: 0.6138 - val_accuracy: 0.7551\n",
            "Epoch 404/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.6967 - accuracy: 0.7131 - val_loss: 0.6248 - val_accuracy: 0.7534\n",
            "Epoch 405/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7270 - accuracy: 0.6913 - val_loss: 0.7337 - val_accuracy: 0.7044\n",
            "Epoch 406/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7375 - accuracy: 0.7035 - val_loss: 0.6305 - val_accuracy: 0.7483\n",
            "Epoch 407/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7297 - accuracy: 0.6954 - val_loss: 0.6392 - val_accuracy: 0.7382\n",
            "Epoch 408/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7265 - accuracy: 0.7006 - val_loss: 0.6508 - val_accuracy: 0.7356\n",
            "Epoch 409/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7644 - accuracy: 0.6781 - val_loss: 0.6174 - val_accuracy: 0.7432\n",
            "Epoch 410/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7114 - accuracy: 0.7104 - val_loss: 0.7460 - val_accuracy: 0.6900\n",
            "Epoch 411/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7208 - accuracy: 0.7002 - val_loss: 0.6286 - val_accuracy: 0.7432\n",
            "Epoch 412/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7230 - accuracy: 0.7029 - val_loss: 0.6295 - val_accuracy: 0.7500\n",
            "Epoch 413/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7292 - accuracy: 0.6948 - val_loss: 0.6356 - val_accuracy: 0.7432\n",
            "Epoch 414/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7477 - accuracy: 0.6921 - val_loss: 0.6172 - val_accuracy: 0.7500\n",
            "Epoch 415/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7361 - accuracy: 0.7025 - val_loss: 0.6236 - val_accuracy: 0.7399\n",
            "Epoch 416/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7263 - accuracy: 0.6979 - val_loss: 0.6321 - val_accuracy: 0.7432\n",
            "Epoch 417/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7247 - accuracy: 0.7004 - val_loss: 0.6151 - val_accuracy: 0.7424\n",
            "Epoch 418/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7169 - accuracy: 0.7033 - val_loss: 0.6178 - val_accuracy: 0.7424\n",
            "Epoch 419/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7151 - accuracy: 0.7002 - val_loss: 0.6110 - val_accuracy: 0.7466\n",
            "Epoch 420/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7170 - accuracy: 0.7048 - val_loss: 0.6449 - val_accuracy: 0.7280\n",
            "Epoch 421/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7216 - accuracy: 0.6969 - val_loss: 0.6257 - val_accuracy: 0.7449\n",
            "Epoch 422/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7071 - accuracy: 0.7048 - val_loss: 0.7405 - val_accuracy: 0.6917\n",
            "Epoch 423/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7634 - accuracy: 0.6850 - val_loss: 0.6487 - val_accuracy: 0.7356\n",
            "Epoch 424/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7170 - accuracy: 0.7063 - val_loss: 0.7392 - val_accuracy: 0.6985\n",
            "Epoch 425/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7229 - accuracy: 0.6988 - val_loss: 0.6802 - val_accuracy: 0.7230\n",
            "Epoch 426/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7182 - accuracy: 0.7065 - val_loss: 0.6120 - val_accuracy: 0.7559\n",
            "Epoch 427/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7423 - accuracy: 0.7000 - val_loss: 0.6290 - val_accuracy: 0.7407\n",
            "Epoch 428/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7121 - accuracy: 0.7077 - val_loss: 0.6216 - val_accuracy: 0.7534\n",
            "Epoch 429/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7318 - accuracy: 0.6975 - val_loss: 0.6301 - val_accuracy: 0.7424\n",
            "Epoch 430/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7282 - accuracy: 0.6867 - val_loss: 0.6184 - val_accuracy: 0.7373\n",
            "Epoch 431/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7049 - accuracy: 0.7075 - val_loss: 0.6259 - val_accuracy: 0.7365\n",
            "Epoch 432/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7215 - accuracy: 0.7015 - val_loss: 0.6240 - val_accuracy: 0.7525\n",
            "Epoch 433/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7296 - accuracy: 0.7025 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
            "Epoch 434/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7382 - accuracy: 0.6983 - val_loss: 0.6394 - val_accuracy: 0.7399\n",
            "Epoch 435/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.6974 - accuracy: 0.7198 - val_loss: 0.6739 - val_accuracy: 0.7162\n",
            "Epoch 436/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7404 - accuracy: 0.6952 - val_loss: 0.6135 - val_accuracy: 0.7601\n",
            "Epoch 437/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7224 - accuracy: 0.7025 - val_loss: 0.6304 - val_accuracy: 0.7449\n",
            "Epoch 438/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7287 - accuracy: 0.7060 - val_loss: 0.6212 - val_accuracy: 0.7525\n",
            "Epoch 439/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7450 - accuracy: 0.6925 - val_loss: 0.6331 - val_accuracy: 0.7407\n",
            "Epoch 440/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7110 - accuracy: 0.7146 - val_loss: 0.6173 - val_accuracy: 0.7441\n",
            "Epoch 441/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7346 - accuracy: 0.6992 - val_loss: 0.6270 - val_accuracy: 0.7365\n",
            "Epoch 442/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7199 - accuracy: 0.7058 - val_loss: 0.7422 - val_accuracy: 0.7061\n",
            "Epoch 443/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7308 - accuracy: 0.6983 - val_loss: 0.7304 - val_accuracy: 0.7069\n",
            "Epoch 444/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7317 - accuracy: 0.6996 - val_loss: 0.6284 - val_accuracy: 0.7297\n",
            "Epoch 445/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7076 - accuracy: 0.7046 - val_loss: 0.6364 - val_accuracy: 0.7407\n",
            "Epoch 446/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7125 - accuracy: 0.7104 - val_loss: 0.6424 - val_accuracy: 0.7407\n",
            "Epoch 447/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7210 - accuracy: 0.6992 - val_loss: 0.6662 - val_accuracy: 0.7196\n",
            "Epoch 448/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7348 - accuracy: 0.6946 - val_loss: 0.6381 - val_accuracy: 0.7365\n",
            "Epoch 449/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7265 - accuracy: 0.7058 - val_loss: 0.6052 - val_accuracy: 0.7466\n",
            "Epoch 450/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7094 - accuracy: 0.7088 - val_loss: 0.6739 - val_accuracy: 0.7247\n",
            "Epoch 451/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7439 - accuracy: 0.6973 - val_loss: 0.6676 - val_accuracy: 0.7247\n",
            "Epoch 452/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7356 - accuracy: 0.7002 - val_loss: 0.6271 - val_accuracy: 0.7416\n",
            "Epoch 453/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7136 - accuracy: 0.7088 - val_loss: 0.6982 - val_accuracy: 0.7103\n",
            "Epoch 454/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7404 - accuracy: 0.7006 - val_loss: 0.6253 - val_accuracy: 0.7441\n",
            "Epoch 455/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7428 - accuracy: 0.6938 - val_loss: 0.6371 - val_accuracy: 0.7331\n",
            "Epoch 456/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7374 - accuracy: 0.6971 - val_loss: 0.6249 - val_accuracy: 0.7399\n",
            "Epoch 457/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7145 - accuracy: 0.7073 - val_loss: 0.6162 - val_accuracy: 0.7432\n",
            "Epoch 458/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7039 - accuracy: 0.7079 - val_loss: 0.6394 - val_accuracy: 0.7238\n",
            "Epoch 459/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7153 - accuracy: 0.7050 - val_loss: 0.6733 - val_accuracy: 0.7297\n",
            "Epoch 460/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7317 - accuracy: 0.6948 - val_loss: 0.6344 - val_accuracy: 0.7483\n",
            "Epoch 461/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7195 - accuracy: 0.7027 - val_loss: 0.6263 - val_accuracy: 0.7416\n",
            "Epoch 462/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7230 - accuracy: 0.7058 - val_loss: 0.6776 - val_accuracy: 0.7204\n",
            "Epoch 463/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7472 - accuracy: 0.6948 - val_loss: 0.6217 - val_accuracy: 0.7449\n",
            "Epoch 464/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7483 - accuracy: 0.6902 - val_loss: 0.6257 - val_accuracy: 0.7365\n",
            "Epoch 465/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7353 - accuracy: 0.6931 - val_loss: 0.6607 - val_accuracy: 0.7204\n",
            "Epoch 466/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7594 - accuracy: 0.6925 - val_loss: 0.6950 - val_accuracy: 0.7027\n",
            "Epoch 467/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7147 - accuracy: 0.6967 - val_loss: 0.6337 - val_accuracy: 0.7407\n",
            "Epoch 468/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7198 - accuracy: 0.6958 - val_loss: 0.6603 - val_accuracy: 0.7272\n",
            "Epoch 469/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7374 - accuracy: 0.6921 - val_loss: 0.7208 - val_accuracy: 0.7069\n",
            "Epoch 470/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7217 - accuracy: 0.7006 - val_loss: 0.6345 - val_accuracy: 0.7340\n",
            "Epoch 471/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7338 - accuracy: 0.6979 - val_loss: 0.6843 - val_accuracy: 0.7188\n",
            "Epoch 472/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7439 - accuracy: 0.6960 - val_loss: 0.6311 - val_accuracy: 0.7441\n",
            "Epoch 473/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7091 - accuracy: 0.7044 - val_loss: 0.7131 - val_accuracy: 0.7052\n",
            "Epoch 474/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7223 - accuracy: 0.6992 - val_loss: 0.6393 - val_accuracy: 0.7272\n",
            "Epoch 475/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7063 - accuracy: 0.7035 - val_loss: 0.6171 - val_accuracy: 0.7475\n",
            "Epoch 476/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7066 - accuracy: 0.7146 - val_loss: 0.6235 - val_accuracy: 0.7449\n",
            "Epoch 477/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7254 - accuracy: 0.6956 - val_loss: 0.6471 - val_accuracy: 0.7340\n",
            "Epoch 478/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7305 - accuracy: 0.6942 - val_loss: 0.6236 - val_accuracy: 0.7517\n",
            "Epoch 479/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7313 - accuracy: 0.6946 - val_loss: 0.6258 - val_accuracy: 0.7475\n",
            "Epoch 480/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7198 - accuracy: 0.7015 - val_loss: 0.6709 - val_accuracy: 0.7204\n",
            "Epoch 481/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7463 - accuracy: 0.6935 - val_loss: 0.6696 - val_accuracy: 0.7230\n",
            "Epoch 482/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7452 - accuracy: 0.6965 - val_loss: 0.6554 - val_accuracy: 0.7188\n",
            "Epoch 483/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7263 - accuracy: 0.7023 - val_loss: 0.7336 - val_accuracy: 0.7019\n",
            "Epoch 484/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7283 - accuracy: 0.6927 - val_loss: 0.6308 - val_accuracy: 0.7365\n",
            "Epoch 485/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7200 - accuracy: 0.7040 - val_loss: 0.6409 - val_accuracy: 0.7365\n",
            "Epoch 486/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7318 - accuracy: 0.6965 - val_loss: 0.6782 - val_accuracy: 0.7196\n",
            "Epoch 487/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.6984 - accuracy: 0.7042 - val_loss: 0.6363 - val_accuracy: 0.7306\n",
            "Epoch 488/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7283 - accuracy: 0.7029 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
            "Epoch 489/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7079 - accuracy: 0.7063 - val_loss: 0.6357 - val_accuracy: 0.7373\n",
            "Epoch 490/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7180 - accuracy: 0.7021 - val_loss: 0.6772 - val_accuracy: 0.7128\n",
            "Epoch 491/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7139 - accuracy: 0.7052 - val_loss: 0.6315 - val_accuracy: 0.7373\n",
            "Epoch 492/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7307 - accuracy: 0.6967 - val_loss: 0.6427 - val_accuracy: 0.7390\n",
            "Epoch 493/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7297 - accuracy: 0.6963 - val_loss: 0.6531 - val_accuracy: 0.7297\n",
            "Epoch 494/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7272 - accuracy: 0.7031 - val_loss: 0.6677 - val_accuracy: 0.7306\n",
            "Epoch 495/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7215 - accuracy: 0.7046 - val_loss: 0.6269 - val_accuracy: 0.7340\n",
            "Epoch 496/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7224 - accuracy: 0.7035 - val_loss: 0.6226 - val_accuracy: 0.7432\n",
            "Epoch 497/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7285 - accuracy: 0.7031 - val_loss: 0.6481 - val_accuracy: 0.7272\n",
            "Epoch 498/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7276 - accuracy: 0.7017 - val_loss: 0.6273 - val_accuracy: 0.7576\n",
            "Epoch 499/500\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.7481 - accuracy: 0.7054 - val_loss: 0.7326 - val_accuracy: 0.7044\n",
            "Epoch 500/500\n",
            "150/150 [==============================] - 18s 121ms/step - loss: 0.7247 - accuracy: 0.6971 - val_loss: 0.6258 - val_accuracy: 0.7432\n"
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "step_size_train=4800//32\n",
        "step_size_val = 1200//32\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_ds,\n",
        "    steps_per_epoch=step_size_train,\n",
        "    epochs=500,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=step_size_val\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate_generator(val_ds, 15)\n",
        "print('Acc: %.3f, Loss: %.3f' % (results[1], results[0]))\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "ASdjzT1W-9Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634e7fbf-b188-483b-ea0a-075f2e072081"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_13772\\3470705721.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  results = model.evaluate_generator(val_ds, 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc: 0.727, Loss: 0.657\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BDQ29FeBm_Dx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "947be2ac-3a1f-4942-a8a3-266a67b7a7e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print()\n",
        "print()\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tI5ecdDenF-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "ecfaee11-b9ae-4bcd-da38-61381fa08973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 91ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m val_labels\u001b[38;5;241m=\u001b[39mval_ds\u001b[38;5;241m.\u001b[39mclass_names\n\u001b[1;32m----> 4\u001b[0m classification \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification)\n\u001b[0;32m      6\u001b[0m matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(val_labels, y_pred)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2125\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2011\u001b[0m     y_true,\n\u001b[0;32m   2012\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2020\u001b[0m ):\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \n\u001b[0;32m   2023\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2125\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2128\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3, 64]"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(val_ds, steps = 2)\n",
        "y_pred = np.argmax(predictions, axis=-1)\n",
        "val_labels=val_ds.class_names\n",
        "classification = classification_report(val_labels, y_pred)\n",
        "print(classification)\n",
        "matrix = confusion_matrix(val_labels, y_pred)\n",
        "df_cm = pd.DataFrame(matrix, index = [i for i in range(3)],\n",
        "                  columns = [i for i in range(3)])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True, linewidths=2.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 100  # 50 in txt-based\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n",
        "\n",
        "predicition = model.predict([prepare('Downloads/haha/doggo.png.png')])\n",
        "\n",
        "def get_class(prediction):\n",
        "    i = 0\n",
        "    for each in predicition[0]:\n",
        "        if (each>0.5):\n",
        "            if(i == 0):\n",
        "                return 'cat'\n",
        "            if(i == 1):\n",
        "                return 'dog'\n",
        "            if(i == 2):\n",
        "                return 'wild'\n",
        "        i+=1\n",
        "    return 'unknown'\n",
        "\n",
        "print(get_class(predicition))"
      ],
      "metadata": {
        "id": "m6uFde-IsRfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "9f0bd7e4-91c5-44d2-a01a-dde721f94e92"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     new_array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img_array, (IMG_SIZE, IMG_SIZE))  \u001b[38;5;66;03m# resize image to match model's expected sizing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_array\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, IMG_SIZE, IMG_SIZE, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# return the image with shaping that TF wants.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m predicition \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDownloads/haha/doggo.png.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_class\u001b[39m(prediction):\n\u001b[0;32m     13\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2fnqy4bt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"conv1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 100, 100, 1)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      â€¢ inputs=('tf.Tensor(shape=(None, 100, 100, 1), dtype=uint8)',)\n      â€¢ training=False\n      â€¢ mask=None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Projeto_Deep_Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}